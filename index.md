# The VOMS Protocol VR Project
Team #3

 Ryan Gorman
 
 Timothy Finnegan
 
 Isak Ohman

## External Advisors
- Dr. Alireza Tavakkoli -- Professor of Computer Science and Engineering at the University of Nevada, Reno
- Dr. Nicholas Murray   -- Assistant Professor of Community Health Sciences at the University of Nevada, Reno

## What is VOMS Protocol VR?

The VOMS Protocol VR project is a system that seeks to be the first step in bringing the concussion diagnosis process into the modern era. Developed for the Vive Pro-Eye in Unreal Engine and the Qt5 UI framework, VOMS Protocol VR (VPVR) takes existing methods of concussion detection and implements them in virtual reality. Currently, the gold standard for rapid concussion detection is the Vestibular/Oculomotor Motor Screening (VOMS) Assessment, a series of exercises with the head and eye that attempt to induce symptoms in a patient in order to quickly identify a concussion. This screening is often done without the assistance of technology, and relies upon a patient's subjective report of his symptoms. With the rise of Machine Learning and Artificial Intelligence, it is possible that this process can be supplanted with an automated system that uses data and modelling to more accurately detect concussions. No such model has thus far been created due to the lack of available research into the topic, and the sparsity of data upon which such a model could be trained. 

The goal of VPVR is to create a platform that can be used to both clinically diagnose concussions, and generate the necessary data with which future projects can train artificial intelligence for automated diagnosis. While the VPVR system administers the VOMS protocol automatically to the patient (with guidance from an attending physician), the eye-tracking sensors within the Vive Pro-Eye headset collect and record information on the patient's eye movements. As eye movement is often noticeably impaired by the presence of a concussion, it is the hope of the VPVR team that this data can be used to train a model that can automatically and accurately detect a concussion at the site in which a concussion has occurred. 

## Interesting VR News
VR Headset Market Size to reach $20 Billion by 2025
https://finance.yahoo.com/news/virtual-reality-vr-headsets-market-101000618.html?guccounter=1&guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&guce_referrer_sig=AQAAACjhlpJRam4uMZ5z_RvbxIQeo_qIrlKyqUiFE3HBREesHVcLFBPIPILNtUh8OOg2JUWFeVu6InESSIJ4GPOkayTyfRH86fVODCRbyM40KX1-4UFlQmrxQJZlYEHifNu7oRTTS0E_uF14a_vRcxB7qOhG2v-r9cEAzABlwjmEy2_s

Sony Patented Asymmetric VR Gameplay
https://uploadvr.com/sony-asymmetric-vr-patent/

Recent Research has Allowed for Smaller and More Efficient VR and AR Devices
https://www.sciencedaily.com/releases/2021/02/210201115943.htm

## Welcome to GitHub Pages

You can use the [editor on GitHub](https://github.com/tfinnegan937/CS425Project/edit/gh-pages/index.md) to maintain and preview the content for your website in Markdown files.

Whenever you commit to this repository, GitHub Pages will run [Jekyll](https://jekyllrb.com/) to rebuild the pages in your site, from the content in your Markdown files.

### Markdown

Markdown is a lightweight and easy-to-use syntax for styling your writing. It includes conventions for

```markdown
Syntax highlighted code block

# Header 1
## Header 2
### Header 3

- Bulleted
- List

1. Numbered
2. List

**Bold** and _Italic_ and `Code` text

[Link](url) and ![Image](src)
```

For more details see [GitHub Flavored Markdown](https://guides.github.com/features/mastering-markdown/).

### Jekyll Themes

Your Pages site will use the layout and styles from the Jekyll theme you have selected in your [repository settings](https://github.com/tfinnegan937/CS425Project/settings). The name of this theme is saved in the Jekyll `_config.yml` configuration file.

### Support or Contact

Having trouble with Pages? Check out our [documentation](https://docs.github.com/categories/github-pages-basics/) or [contact support](https://support.github.com/contact) and weâ€™ll help you sort it out.
